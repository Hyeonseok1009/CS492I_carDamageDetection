{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VNbcTboKTbPgWd7zbZAhGjnQpL6b9xxj","timestamp":1670132735734}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qLhqVDwdQVOs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670134495619,"user_tz":-540,"elapsed":2759,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"a8ef8e30-244f-4f17-82c9-f804d44e5e12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["\n","# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n","# login with your google account and type authorization code to mount on your google drive.\n","import os\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","\n"]},{"cell_type":"code","source":["!fusermount -u drive\n","!google-drive-ocamlfuse drive\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","from pandas.core.common import flatten\n","import copy\n","import numpy as np\n","import random\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","\n","import glob\n","from tqdm import tqdm"],"metadata":{"id":"-dzF2lDAcJsi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670138258083,"user_tz":-540,"elapsed":546,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"50bff8fb-2beb-49ed-ead4-426ea74a68ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fusermount: failed to unmount /content/drive: Invalid argument\n","/bin/bash: google-drive-ocamlfuse: command not found\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"v15kItQLi2uk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# do not run below"],"metadata":{"id":"0fOGGudHcrOX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import torch.nn as nn\n","import torchvision.models as models\n","\n","class inception(nn.Module):\n","    def __init__(self, train_inc=False, num_classes=3):\n","        super(inception, self).__init__()\n","        self.train_inc = train_inc\n","        self.inception = models.inception_v3(pretrained=True, aux_logits=True)\n","        self.inception.dropout=nn.Dropout(0.3)\n","        self.inception.fc = nn.Linear(self.inception.fc.in_features, num_classes)\n","        \n","        self.dropout = nn.Dropout(0.2)\n","        self.soft = nn.Softmax()\n","\n","    def forward(self, images):\n","        features = self.inception(images)\n","        features_2 = self.dropout(features)\n","        return self.soft(features_2).squeeze(1)"],"metadata":{"id":"WHgKuaR5crhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"id":"r12ZaRTVcr1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","\n","from tqdm import tqdm\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"jBljy0NGcsGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gnQOkYfNnl3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","        [\n","            transforms.Resize((356, 356)),\n","            transforms.RandomCrop((299, 299)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","        ]\n","    )"],"metadata":{"id":"M9OHiLAxnl_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install kora -q\n","from kora import drive\n","drive.link_nbs()\n","\n","\n","\n"],"metadata":{"id":"GKVLiwLyou5A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670134441954,"user_tz":-540,"elapsed":40794,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"a4dc93f7-850d-4ba0-b6be-ea4c219a6f2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 57 kB 950 kB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 37.5 MB/s \n","\u001b[?25hMounted at /content/drive\n"]}]},{"cell_type":"code","source":["device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"8A3-mrNqyqb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import location_dataset\n","# from location_dataset import *\n","# importing wasnt really useful"],"metadata":{"id":"zVR8L4gyo3an"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import os\n","from PIL import Image\n","import torch\n","\n","class Damage_location(Dataset):\n","    def __init__(self, root_dir_front,root_dir_side, root_dir_rear, annotation_file, transform=None):\n","        self.root_dir1 = root_dir_front\n","        self.root_dir2 = root_dir_side\n","        self.root_dir3 = root_dir_rear\n","        self.annotations = pd.read_csv('/gdrive/MyDrive/project/' +annotation_file)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_id = self.annotations.iloc[index, 0]\n","        value = self.annotations.iloc[index, 1]\n","        if value ==0:\n","          root_dir = self.root_dir1\n","        elif value == 1:\n","          root_dir = self.root_dir2\n","        elif value ==2:\n","          root_dir = self.root_dir3\n","        img = Image.open(os.path.join(root_dir, img_id)).convert(\"RGB\")\n","        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return (img, y_label)"],"metadata":{"id":"es7-gFjF_iNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root2= '/gdrive/MyDrive/project/car-damage-dataset/data2a'\n","training = root2+'/training'\n","# we then split the training in train, valid so we store everything in the training folder\n","front = '/00-front/'\n","rear = '/01-rear/'\n","side = '/02-side/'\n"],"metadata":{"id":"6vW7RqvuAEhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%store -r learning_rate\n","num_epochs = 40\n","learning_rate = 0.0001\n","train_CNN = False\n","batch_size = 32\n","shuffle = True\n","pin_memory = True\n","num_workers = 1\n"],"metadata":{"id":"G_2wvrS0zE3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = Damage_location(training+front,training+side,training+rear,\"damage_locations.csv\",transform=transform)\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ev3FBA6fAwR-","executionInfo":{"status":"ok","timestamp":1670138565067,"user_tz":-540,"elapsed":2,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"0e9e6159-2b02-4a72-ad12-8e39e2142309"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Damage_location object at 0x7f26c04ebc10>\n"]}]},{"cell_type":"code","source":["dataset = Damage_location(training+front,training+side,training+rear,\"damage_locations.csv\",transform=transform)\n","train_set, validation_set = torch.utils.data.random_split(dataset,[1000,150])\n","train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n","validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)"],"metadata":{"id":"uWh1Yg6NcsoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mewC_13c5vB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = inception().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","for name, param in model.inception.named_parameters():\n","    if \"fc.weight\" in name or \"fc.bias\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = train_CNN"],"metadata":{"id":"FYann6LBovSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_accuracy = 1\n","# i do not want to update my weights now"],"metadata":{"id":"MryK2TPrq71u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_accuracy(loader, model):\n","    if loader == train_loader:\n","        print(\"Checking accuracy on training data\")\n","    else:\n","        print(\"Checking accuracy on validation data\")\n","\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","    root = '/gdrive/MyDrive/project/car_damage_location/'\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","\n","            scores = model(x)\n","            # print(scores)\n","\n","            # predictions = torch.tensor([1.0 if i >= 0.5 else 0.0 for i in scores]).to(device)\n","            \n","            predictions = torch.tensor([torch.argmax(score) for score in scores]).to(device)\n","            print(predictions)\n","\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","            ratio = float(num_correct)/float(num_samples)\n","            if loader != train_loader:\n","              global max_accuracy\n","              if ratio>= max_accuracy:\n","                max_accuracy = ratio\n","                print('max accuracy is:', max_accuracy)\n","                torch.save(model.state_dict(), root+'model_location_weights.pth')\n","    return f\"{float(num_correct)/float(num_samples)*100:.2f}\"\n","    print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n","    model.train()"],"metadata":{"id":"bqHNJwfnq7-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-5h4oFTAq8j4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","    model.train()\n","    for epoch in range(num_epochs):\n","        loop = tqdm(train_loader, total = len(train_loader), leave = True)\n","        if epoch % 5 == 0:\n","            loop.set_postfix(val_acc = check_accuracy(validation_loader, model))\n","        for imgs, labels in loop:\n","            imgs = imgs.to(device)\n","            labels = labels.to(device)\n","            labels=labels.to(torch.int64)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n","            loop.set_postfix(loss = loss.item())\n"],"metadata":{"id":"HFhtqblMtVKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oSLjAUjfGFnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train()"],"metadata":{"id":"x5-6dCKmGFwz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train()"],"metadata":{"id":"VbLAlM1hIKbY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img =Image.open('/gdrive/MyDrive/project/car-damage-dataset/data2a/training/02-side/0257.jpeg')"],"metadata":{"id":"zSoinet-GqfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img.show()"],"metadata":{"id":"V1Qsi34UIKn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(img):\n","  img = transform(img)\n","\n","  return img\n"],"metadata":{"id":"D_1OJ1kT1c2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model_loaded = inception()\n","# path ='/gdrive/MyDrive/project/car_damage_location/model_location_weights.pth'\n","# model_loaded.load_state_dict(torch.load(path), map_location=torch.device('cpu'))\n","\n"],"metadata":{"id":"0DzC9Z9WxGaG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test\n","import urllib\n","\n","from urllib.request import Request, urlretrieve  # Python 3\n","model_loaded=model\n","\n","def test(image_path):\n","    \n","    urlretrieve(image_path, 'save.jpg') # or other way to upload image\n","    # Image.open('save.jpg')\n","    img = transform(Image.open('save.jpg'))\n","    img = img.to(device)\n","    img = img.unsqueeze(0)\n","\n","\n","    with torch.no_grad():\n","      output = model_loaded(img)\n","      # print(output)\n","      if output[0].argmax()==0:\n","        return ' Front damage '.format(output[0] * 100)\n","      elif output[0].argmax()==1:\n","        return ' Side damage '.format((1-output[0]) * 100)\n","      else:\n","        return ' Rear damage '.format((1-output[0]) * 100)\n","\n","\n","\n","\n"],"metadata":{"id":"2Ss1Hee9tVTC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url='https://res.cloudinary.com/debi2p5ek/image/upload/w_1140/v1/1984/37086-sideswiped_car_largeoriginal-6f27d022.png'\n","# url2 = 'data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxAQEA8PEBAPDw8NDw0PDQ0PDw8NDw0PFREWFhURFRUYHSggGBolHRUVITEhJSkrLi4uFx8zODMtNygtLisBCgoKDg0OFRAQFS0dFx8tLS0tKy0tNy0rLS0tLS0rLi0rKy0tLS0tKy4tKystKy0rMSsrKy0rKy0tLS0rLS0tLf/AABEIAJYBTwMBIgACEQEDEQH/xAAcAAABBQEBAQAAAAAAAAAAAAAEAAECAwUGBwj/xAA9EAACAgEBBQYDBgQEBwEAAAABAgADBBEFEiExYQYTIkFRcQeBkRQjMkKhsTNScoJjweHwNGKSorLC8ST/xAAaAQADAQEBAQAAAAAAAAAAAAAAAQIDBAUG/8QAIhEBAQEBAAICAQUBAAAAAAAAAAECEQMhEjEEIkFRYfAU/9oADAMBAAIRAxEAPwDuMczQoMyqGmhS05nfWnUYSsBpaGVmUirhHkRJQRSjR5EmAS1jGR3ot6A4Gy69RMHKxVbvKnH3d6lH6a8j8jOisMys6vWKtcXjxPPwWotsqbnWxX36xkE7Dt3galMgD8Q3Lf6hyP0nKKkxsenjXZKkkvWVKJaoiaJaRiJMCIiIB2WR3YQVkdyMka4UhlAWXVwOLI2kkBJaQCrSLSWaSDQTXLbW/iN7zMYzS2z/ABGmW00jHRaxExoxMaSMg0cyDRpqDmFbCymS9EA1Fzom6ToN7eG63uDA3M3/AIbYve7VxAVDrWz2up4ghUOn6kS4w8l5HrGLdvDjwZeDD0MsdAeYmntTZ4LO9Q0ZdNV/nT1/eZQaaPNs4AzcDXinAj0gtObZWdLBqPWbcruoVhxEnh9/lVTlK44ESZmVk7NZDvVn5eUbH2kR4bBofXyh0c/hpsAZn5Oz1biNVPqOEPRww1B1jMIya1DQ6l5kU2Q6qyYvS1GvTZDanmPVZDarY2djTVpPegSWy0Wxo4vLStmlZtlL2wORcbJHvYK9spa6JXBr2wLJeVtdKLbIKmWdtWgW12Vn8w8PRhynnrUkEg8wSDPRLz5zmO0GHu2BwPDaN75+cz07PFeemGEkwkvFckK5DoUbsfdl+5GKQNQVjbsvKRisCVBZJRJaRCMk1EnpGSTiPqBEqcS9pTZAnJbaP3rTKYzT22fvWmW00jHf2UUaKUgjK2kzK3jiaqsM9H+B2z967JySOFarUp6ni3/rPNLWnvnwp2Z9n2bUSNHyCbW9eJ1H6aS45PLp1Vh8aDgNdQfUjnpOfvp04jkWce2hM1qUNuUgHKsFj7ngP01MB0/j1czW7HX+6bZzLL/Li3foDG3pMrISAWsHycRH5gS8iNEGHdRZUdU4r6S/H2kCPF4T1mowBgOVs9W5cDFzn0rsv2LR4XTbM1WlqWTF61jZqthVd0xa7oSl0bO4bCXy0XzJW6WC6NPwaRukGugXexjZATIhrJU1kqLxtYlTKReMYwEmqwUqavWBbXw9+huHiqO8PbzmwtcurxwdQeTAg/OHB8+POlrku7mhk4m47L/KSJUa5nx1zQQpIlIWa5Bq4cV0KVkCsKKSpliAZhGlriVGASQy0GUCWgwCTQeyXEyi0wDkNsn71veZhh+1TrY/vADNIw39mjxoo0GMqcyxjKLWlRG6s2bhnIyKaBxN1iqf6fP9NZ9LLu01Ig4KihR7AcZ4z8INmd5lvksPDQu6p/52/wBP3nsGH/8Aoyd0ca6NGf0L/lX6jX5dZpI4PJr20+z9e677w+8Yd4//AC68FH0Ep7Q1JWe8AA3lcOR5nnqZriju21I/ikAt6HTgJm9orglTbwBBDA6+XCb5z7jnuuxy6OCAfUaiJxM3s3lC3HU/ylkP9rETSPCZGbdjFY4MRMQVmVsZa0qaBAi0dXlDNGDzme7wary9LZnq8uR4C5aSWy1bJno8vR403I4PJBoMhlyRpsXAyYEatYRWkaeoKkuSuWJVCEqgi6V11wumuJK4Qixotc1t/C+83tPxDX5zGbHnabVp3lB9Jg248mxt49+mI1Mqeqa1lMHsqk8bzTKdJQ6TRtrg1iRNJQDrB3EOsWC2CJSkGSBkDFrAlhMotbnJM8FyLNFPsYByec2rsepghhF51J9zBzNIw0aIxoxMaEXMEuaXWtDuyWzTk5da6aqpDv6aDlLzHN5dvVOxWH9h2ep01uuOoUc2sbkJ6T2X2UaahvcXJ37G/msPP5Dl7Cc32fwe+tFumtWMCtI8t7k1ny5D3M9ATRV6Ac5vzjg1rt4a1wNNeJHEdJwHxOzDVjDyDkgHrO1tfgWPDzM8L+LPalrmNII3KCyJu/mc8yfYcPnL58c2lj9Wou+GWVv02r6WMw9iZ2bCec/CyzQuv8yz0czBWvuqSJEy0ythAkCZBjJmQMAxWaMGkWMiDOV9BIvV5ejwRTLkMD4MraEVmB1mGVCNFguuF1LB6FmhQkqMdVZTXDaqpGiuH1JKY6qNdMuWqWKssAj4yulQSS0k9IxEaeqrl1BEybqpsNAr1irTNY9tcEtrmpcIDdJsb5rMuSA2iaN5mde0it80HbBLYRa8CtsktYrcypnkLbYLZdAL3sgebd4G9pB75n5+RqNI01nPKGk3aVM0uMaRlbtHJg9rypGW9ciq1p6J2B2U4rCoNL8vXxedVQ5t/kOpnF9m9mNl5VVKjXfdQfTn5z6G7F9nPsqvkXgFgd2tU4ghTooHTz9/ab4y87y+R0OLipi0JSOB3RvnoPKX4zeA6kks2oHkogv2Gy7fsL+LQlF/LveQ9uAEr2rnjGoa5wAUQagct7T9p08nOfu5O23rnPiR2lGPT3KH72zhz5T552tlmx+eoXUA+p8zNvtbt58ix7GJ3rCd0fyp6/OcsJj5Nd9T6jrzn45/uvQPhy2646gz0xLZ5p2EXRl9jO/Vpmi/Y3WRaVrZJb0RItIMJNpXrAMJpGV03BgCJZOV9FEhLklSy6uAoqoQ6hYHSIfRHGWh2Os0qFgFE0aDLjn0NpEMrEEpMMQyoxq1ZOQBktY2VPImItKntEBIdzAr2iuyRM7IyhE1zkr3mZkXSOVmdZj5Wb1k2ujOV2TkTLyMiD5ObMvJzesi10SCr8iA3ZMAvzOsBtyolNC7KgdmTAbMiDvfDhWjLMiBXXayl7ZS1kuRlraxnlZaVPaBzMGfK9Br1MuZc+/LJ90WzwWxtZQzk8z8pXNJlyb83fp6z8Hdid67W6Me7Yb+mqnoAZ7o+rhUC7igABR+UTyv4Bba+4vx2C61lXWzTxFST4T66eXvPWjeBxHn5zpz6k5HDu21JW3BpwBA49J5D8Xu2GgfAqZSngbKsHE68xSP0J6Te+JXbJcaoU49iNk3bwKg6mkDm7+gnz7tTNNrHiSASd483Y82MWr8Z/da+LHf1X6ga+0uxY8z+nSRrHESMvw01dR149B5mYNrXovYurTQ9J2O9OT7CObFst5Vhu7qHqBzb6zqiYMquDSStKA0mDEF+9GIlQaOHgHE4tpU9PMTVrs1mNXDKH0nI+jrTQwiswGt4VU0aa0KTDqDMypoZTZKjPTWpaHU2TGruhCZEpjY3arYWl4nL5e166K3ttcJXWNWY/tp5npOaxNuZ20ra66LU2bRkFvs7uFszcsAElq0J0VdAeJ05cCTwlT2x1JPdeo/aBItmCeZdpeyC49KXWX7VyHs13mfNFQrYc1ICH3HPXj6TF2dszaJoGTh5eSFLWAUZNgykbcZV/FoPxEkABdfCeXOVc1nNY/l67dtAesAv2l1nnWzO11juaMlO4yF5r+Szqp/+9DD7tqdZna6c+OX26XI2l1mXlbT6znr9pdZm5G0esnraeNuZW0usyMnaPWY9+d1gF2VEvkjTvzusAuy+sAfIg72w4V3ILsyIO90HayVGyVMsteQQ1sqayD2Wgc4O+QTy4dZcy59+eQVZcBzMGfJJ5fWUGNNJmOTfm1r69HJ158Yot314fvFven185TFID5e8QUHzEhGgHrnwX8Ay3J0ARFJPIakn/KE9qfiE7u2Ph2FK0BRr+e8fMLPO9mbXsqxLMaslBe4e+wc9wDQKJVhtqdeQUaKPSXPJZJDnjn3UNp3PqxZyzWHV2J1Yj01mbCdoPq3tBhM7erOJv7MwtzHsvYcbFK1DoeH6mZ2ycE3WKn5ebn0WdatYuysfGUeCv71x5BV/CPrAtV1nZzB+z41NXmFBbqx4maJMYekYwQcmOGkIxgF29ETKgZLWIOMQwitoIrS5HnI+i60KnhVdkzK7JelsZVq12whLpjrfJjJlJsbYyYzZcxWy5RZm9YJ4lk1nPzqcZ9TjYy9/cmugus1AVGPkNXrBPo5ladnrjk15gzdWFldrMtLUWUqK67EWtSSBp3laheQB89CJmW5zJTtI1sy3d1XYrIxR91bsYtoRx/CjfQyfYHbN+ZZbi2WPdc/cvjixyx3U7wOu8f61P8Ab0nZ+LnOtZmryd9vK/O3qd+M9yensPZjald4sx7VV2OrKH8e+p5jj5gkn08R0AEltrs2orsbCb7JaKrUXcO5TuuwZlC8qySNd9dDrxgmxOyzVMttlmli8UVOIB0/MfOcpt3aeRbY6XuSa2KmseFAQdOCjh856P8Ay+P8jzWeHXMz/enmf9G/D4pfLn3/AL7eZVZCtZ9lIdWqa3uXc+Ou1WYtWTrqQeP9w6nXbOYwA3uB0Gv+/r9Jz+0rAdreHT/i8dTp5uCiv/3BpvdqQKxikcGsxhYw97G4/XenkebPL6e3+D5Lc2ULdmdYFblQN75Q9sx47LsS98oe2UNZKy8qZZa8i5rJWzylrNJQ9x8vrLmXPvzSCHtA5wd7yeXCVGNLmY5deW08bWPp68It70+vnKZFp68P3i3vTh+8iYoA4/eaODsW60Fgp3VDMTyGgGvP5QXE0V1Y6aL4jqNdemkOyNvWmvuaya6zqX0PjsJ9T6acNBALttYOPQqIlgsu13rNNdAu6fpx04c5iKNSB6x2PP5CToHn6cB7wAmx+SjgB+p9TDMbgpmfXxMPsOixNAFx1YxlEU2NgYW83eN+FOXUwDX2ZjjHpJbg7Dec+g9Jq9gaC/f5bc7W3U6Is5jtJneEVjnZz6LPRez2IKsalB+VBr7xs60iY2sYmR3ogmWkSZAnSMWgE96TDQfekg0A4wNJiyBd7GN05H0HWiLpL7RMs3yByIx1rfapFsuZByJA5EC61my+spfK6zKbIlbXwL5QdZkaOLAAw3SlqHk9ZBBB6aEj2JmHfXbiW130O6hXDY+QvBlYcd1tOTjzHn7GFm+XY2Wo1BIUNoHUqLKnAOoDIQQfpw8is1xrjj/I8Xz9z7eg7C+NyhAudjWGxQAbcYoRZ1KMRofYznu13xFpyLHtw8e2t7FUd7eyeBhw31rXUb2mnEtw56TNxOz2NeRuoOoozO71/tsrs3f+szYbs3gY6hrPsmOV47+XnNtK5v6cWlEB/u1HqDOjHl+HbnXHDr8fWvWo5Tsvs1mdb21AO/3JPNm5Nb/Sup4/zbo9dCu1G1RkZDMv8OtUppH+Gg5/Mlj85Lbe3K2DV43ebraCzIt3RbcBwACrwrQDgFHIcgOOvPlphf1V2eOTx55+60vIF5WWkGfSEideRYWlL3enGVu5Pt6SEuZc+vLb9HJ15xExhH10lMS0i19PrIkxQBRCIyVfP2BP6Rg2nDXqI0l+UdSYycxEFh/N8l/39JWI5PD3JJkYApb09P3kF4cfpJLA4JxV4y/LbyjYiyvIbUxKNi0F2Cjz/QTpnZaq90cAo1YwTZWN3ab7fiblM/bWVr92Dz4v/kIyoLvTberH81iAD0GoGk9roGiqPRR+08U2Wut9A/xa/wDyntfkPYRJSJkCfWMYxOsAWsixkdSOERPpAH3pEGR19JHX6wDz82SBtiinM93qDWyBsiijTagbZBrI8UaLVZeRLxoo+ItqJeQLxRSmdtQYyOseKNnaYmMTFFGi1Bn0lBMUUqMN32WsWkUUaCJjRRQBSWnLrrFFAGfmfcx18/aKKME/l7SMUUQKSQA66/KKKAIn/STQRRRKjRqGiyzZeOLLNTyU8oooG0do5G6Dw4IOAnM2OSSTzPOKKNI7s6uuXjj/ABFnspEaKIkDwkH4xRRhX3nkZFjpFFEDH1HCMeMUUA//2Q=='\n","test(url)\n","# test(url2)"],"metadata":{"id":"6eLFFRMm2mJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C_wMHqJ0_V7I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6oJGOSPu_wrc"},"execution_count":null,"outputs":[]}]}