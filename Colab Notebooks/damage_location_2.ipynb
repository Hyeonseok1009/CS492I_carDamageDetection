{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11Rco10sBHR02u_KOx8yQHuWFgElaM3gk","timestamp":1670145271603},{"file_id":"1VNbcTboKTbPgWd7zbZAhGjnQpL6b9xxj","timestamp":1670132735734}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qLhqVDwdQVOs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670680634248,"user_tz":-540,"elapsed":4443,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"4e77be33-060a-4340-c693-479bbd67563e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["\n","import os\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","\n"]},{"cell_type":"code","source":["!fusermount -u drive\n","!google-drive-ocamlfuse drive\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","from pandas.core.common import flatten\n","import copy\n","import numpy as np\n","import random\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","\n","import glob\n","from tqdm import tqdm"],"metadata":{"id":"-dzF2lDAcJsi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670680634248,"user_tz":-540,"elapsed":5,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"4a0b3780-dde4-4253-9bf6-17d138a281f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fusermount: failed to unmount /content/drive: No such file or directory\n","/bin/bash: google-drive-ocamlfuse: command not found\n"]}]},{"cell_type":"code","source":["# Model\n","from torchvision.models import resnet50, ResNet50_Weights\n","\n","import torch.nn as nn\n","import torchvision.models as models\n","\n","class inceptionv3(nn.Module):\n","    def __init__(self, train_inceptionv3=False, num_classes=3):\n","        super(inceptionv3, self).__init__()\n","        self.train_inceptionv3 = train_inceptionv3\n","        self.inception = models.inception_v3(pretrained=True, aux_logits=True)\n","        self.inception.dropout=nn.Dropout(0.3)\n","        self.inception.fc = nn.Linear(self.inception.fc.in_features, 1024)\n","        self.dropout = nn.Dropout(0.2)\n","        self.linear =nn.Linear(1024,num_classes)\n","\n","    def forward(self, images):\n","        features = self.dropout(self.inception(images))\n","        features_2 = self.linear(features)\n","        return features_2.squeeze(1)"],"metadata":{"id":"WHgKuaR5crhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","\n","from tqdm import tqdm\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"jBljy0NGcsGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transform\n","transform = transforms.Compose(\n","        [\n","            transforms.Resize((356, 356)),\n","            transforms.RandomCrop((299, 299)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","        ]\n","    )"],"metadata":{"id":"M9OHiLAxnl_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install kora -q\n","# from kora import drive\n","# drive.link_nbs()\n","\n","\n","\n"],"metadata":{"id":"GKVLiwLyou5A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670642173353,"user_tz":-540,"elapsed":15196,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"6e816569-9231-48a9-c549-b28385087e1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 26.3 MB/s \n","\u001b[?25hMounted at /content/drive\n"]}]},{"cell_type":"code","source":["device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"8A3-mrNqyqb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zVR8L4gyo3an"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset class\n","from torch.utils.data import Dataset\n","import pandas as pd\n","import numpy\n","import os\n","from PIL import Image\n","import torch\n","\n","class Damage_location(Dataset):\n","    def __init__(self, root_dir_front,root_dir_side, root_dir_rear, annotation_file, transform=None):\n","        self.root_dir1 = root_dir_front\n","        self.root_dir2 = root_dir_rear\n","        self.root_dir3 = root_dir_side\n","        self.annotations = pd.read_csv('/gdrive/MyDrive/project/'+annotation_file)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_id = self.annotations.iloc[index, 0]\n","        # print(self.annotations.iloc[index, 1][1:-1])\n","      \n","\n","        value = numpy.fromstring(self.annotations.iloc[index, 1][1:-1], dtype=float, sep=' ')\n","        # print(value)\n","\n","        value = torch.from_numpy(value)\n","        # print(type(value))\n","\n","        # print(value)\n","        if value[0] == 1:\n","          root_dir = self.root_dir1\n","        elif value[2] == 1:\n","          root_dir = self.root_dir2\n","        else:\n","          root_dir = self.root_dir3\n","        img = Image.open(os.path.join(root_dir, img_id)).convert(\"RGB\")\n","        npp = numpy.fromstring(self.annotations.iloc[index, 1] [1:-1],dtype=float,sep = ' ')\n","        y_label = torch.from_numpy((npp))\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return (img, y_label)"],"metadata":{"id":"es7-gFjF_iNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root2= '/gdrive/MyDrive/project/car-damage-dataset/data2a'\n","training = root2+'/training'\n","# we then split the training in train, valid so we store everything in the training folder\n","front = '/00-front/'\n","rear = '/01-rear/'\n","side = '/02-side/'\n"],"metadata":{"id":"6vW7RqvuAEhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 40\n","learning_rate = 0.02\n","train_CNN = False\n","batch_size = 64\n","shuffle = True\n","pin_memory = True\n","num_workers = 1\n"],"metadata":{"id":"G_2wvrS0zE3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = Damage_location(training+front,training+side,training+rear,\"damage_locations_3.csv\",transform=transform)\n","train_set, validation_set = torch.utils.data.random_split(dataset,[960,190])\n","train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n","validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)"],"metadata":{"id":"uWh1Yg6NcsoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_set)"],"metadata":{"id":"mewC_13c5vB5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670147482515,"user_tz":-540,"elapsed":489,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"40cd6947-5a1c-4aa9-986c-3d9b1bfea961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<torch.utils.data.dataset.Subset object at 0x7f8c9541bf40>\n"]}]},{"cell_type":"code","source":["model = inceptionv3().to(device)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","for name, param in model.inception.named_parameters():\n","    if \"fc.weight\" in name or \"fc.bias\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = train_CNN"],"metadata":{"id":"FYann6LBovSF","executionInfo":{"status":"ok","timestamp":1670680729167,"user_tz":-540,"elapsed":437,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"747655ca-aca2-481e-d3fe-028b2b1c07ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["# only save new weights if the accuracy is > 75% \n","max_accuracy = 0.75"],"metadata":{"id":"MryK2TPrq71u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.parameters)"],"metadata":{"id":"jEHqSz_uRgOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy"],"metadata":{"id":"_trBpkG8c9ZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function used for evaluating during training\n","def check_accuracy(loader, model):\n","    if loader == train_loader:\n","        print(\"Checking accuracy on training data\")\n","    else:\n","        print(\"Checking accuracy on validation data\")\n","    num_classes =3\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","    root = '/gdrive/MyDrive/project/car_damage_location/'\n","    with torch.no_grad():\n","        for x, y in loader:\n","            # print('hhh')\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","\n","            # x =x.type(torch.FloatTensor)\n","            # y =y.type(torch.FloatTensor)\n","\n","            scores = model(x)\n","\n","\n","            # predictions = torch.tensor([1.0 if i >= 0.5 else 0.0 for i in scores]).to(device)\n","            t1 = torch.tensor([1.,0,0])\n","            t2 = torch.tensor([0,1.,0])\n","            t3 = torch.tensor([0,0,1.])\n","            prediction_list =[]\n","            for score in scores:\n","              max_index = score.argmax()\n","              if max_index == 0:\n","                prediction_list.append(t1)\n","              elif max_index ==1:\n","                prediction_list.append(t2)\n","              else:\n","                prediction_list.append(t3)\n","            # print(prediction_list)\n","            predictions = torch.stack(prediction_list).to(device)\n","            \n","            for sample in range(predictions.size()[0]):\n","              if torch.equal(predictions[sample],y[sample]):\n","                num_correct += 1\n","            num_samples += predictions.size(0)\n","            print('num of correct: ', num_correct, ' num of samples: ', num_samples)\n","            ratio = float(num_correct)/float(num_samples)\n","            if loader != train_loader:\n","              global max_accuracy\n","              if ratio>= max_accuracy:\n","                max_accuracy = ratio\n","                print('max accuracy is:', max_accuracy)\n","                torch.save(model.state_dict(), root+'model_location_weights_final_2.pth')\n","    return f\"{float(num_correct)/float(num_samples)*100:.2f}\"\n","    print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n","    model.train()"],"metadata":{"id":"bqHNJwfnq7-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training function\n","def train():\n","    model.train()\n","    for epoch in range(num_epochs):\n","        loop = tqdm(train_loader, total = len(train_loader), leave = True)\n","        if epoch % 2 == 0:\n","            loop.set_postfix(val_acc = check_accuracy(validation_loader, model))\n","        for imgs, labels in loop:\n","            imgs = imgs.to(device)\n","            labels = labels.to(device)\n","            labels=labels.to(torch.int64)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels.float())\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n","            loop.set_postfix(loss = loss.item())\n"],"metadata":{"id":"HFhtqblMtVKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    train()"],"metadata":{"id":"x5-6dCKmGFwz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train()"],"metadata":{"id":"UcvfcZGhVQ5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(max_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yYQEy-DiPT2","executionInfo":{"status":"ok","timestamp":1670681954862,"user_tz":-540,"elapsed":2,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"e7f540a4-7a85-48b8-9e91-80e0eea9b843"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.75\n"]}]}]}