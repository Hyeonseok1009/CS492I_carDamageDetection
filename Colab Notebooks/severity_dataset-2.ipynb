{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1U2aQT8qvi-ds1dNW6WRe6lVb-QgqNPi6","timestamp":1670564348034}],"authorship_tag":"ABX9TyP6j9NDWYwHLc6k3xOty8cQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nSSlfp25r9u3","executionInfo":{"status":"ok","timestamp":1670138669936,"user_tz":-540,"elapsed":6564,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"65299444-aaad-45ec-a46f-e999f8f76588"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["\n","# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n","# login with your google account and type authorization code to mount on your google drive.\n","import os\n","from google.colab import drive\n","drive.mount('/gdrive')\n"]},{"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","from pandas.core.common import flatten\n","import copy\n","import numpy as np\n","import random\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","\n","import glob\n","from tqdm import tqdm"],"metadata":{"id":"j1DAQkfztWBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import torch\n","root2= '/gdrive/MyDrive/project/car-damage-dataset/data3a'\n","training = root2+'/training'\n","# we then split the training in train, valid so we store everything in the training folder\n","front = '/00-front/'\n","rear = '/01-rear/'\n","side = '/02-side/'\n","\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","train_df = pd.DataFrame(columns=[\"img_name\",\"label\"])\n","train_df_2 = pd.DataFrame(columns=[\"img_name\",\"label\"])\n","train_df_3 = pd.DataFrame(columns=[\"img_name\",\"label\"])\n","\n","\n","\n","max_idx=0\n","max_idx_2=0\n","train_df[\"img_name\"] = os.listdir(training+front)\n","for idx, i in enumerate(os.listdir(training+front)):\n","    train_df['label'][idx] = 0\n","    # if idx>max_idx:\n","    #   max_idx = idx\n","\n","# print(train_df)\n","\n","train_df_2[\"img_name\"] = os.listdir(training+rear)\n","for idx, i in enumerate(os.listdir(training+rear)):\n","    train_df_2['label'][idx] = 2\n","\n","\n","train_df_3[\"img_name\"] = os.listdir(training+side)\n","for idx, i in enumerate(os.listdir(training+side)):\n","    train_df_3['label'][idx] = 1\n","\n","\n","# print(train_df_2)\n","frames = [train_df,train_df_2, train_df_3]\n","result_train_df = pd.concat(frames)\n","result_train_df=result_train_df.sample(frac=1).reset_index(drop=True)\n","print(result_train_df)\n","result_train_df.to_csv(r'/gdrive/MyDrive/project/'+'damage_severity.csv', index = False, header=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgXuTQP4tWU5","executionInfo":{"status":"ok","timestamp":1670140358455,"user_tz":-540,"elapsed":490,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"caf8167c-61ec-42c3-d6c3-4ddacf041e15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       img_name label\n","0     0088.JPEG     0\n","1     0032.JPEG     2\n","2     0202.JPEG     0\n","3     0071.JPEG     1\n","4     0182.JPEG     2\n","...         ...   ...\n","1145  0034.JPEG     0\n","1146  0081.JPEG     2\n","1147  0130.JPEG     1\n","1148  0364.JPEG     0\n","1149  0005.JPEG     0\n","\n","[1150 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["print(result_train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Fz96EwJHyU3","executionInfo":{"status":"ok","timestamp":1670140362844,"user_tz":-540,"elapsed":2,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"98eee831-d694-425e-adde-41fa0c6310c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       img_name label\n","0     0088.JPEG     0\n","1     0032.JPEG     2\n","2     0202.JPEG     0\n","3     0071.JPEG     1\n","4     0182.JPEG     2\n","...         ...   ...\n","1145  0034.JPEG     0\n","1146  0081.JPEG     2\n","1147  0130.JPEG     1\n","1148  0364.JPEG     0\n","1149  0005.JPEG     0\n","\n","[1150 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import os\n","from PIL import Image\n","import torch\n","\n","class Damage_location(Dataset):\n","    def __init__(self, root_dir_front,root_dir_side, root_dir_rear, annotation_file, transform=None):\n","        self.root_dir1 = root_dir_front\n","        self.root_dir2 = root_dir_rear\n","        self.root_dir3 = root_dir_side\n","        self.annotations = pd.read_csv(annotation_file)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_id = self.annotations.iloc[index, 0]\n","        value = self.annotations.iloc[index, 1]\n","        if value =='front':\n","          root_dir = self.root_dir1\n","        elif value == 'rear':\n","          root_dir = self.root_dir2\n","        else:\n","          root_dir = self.root_dir3\n","        img = Image.open(os.path.join(root_dir, img_id)).convert(\"RGB\")\n","        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return (img, y_label)"],"metadata":{"id":"NQn79wC8t_HZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","\n","from tqdm import tqdm\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"KI1PvlvYubxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","        [\n","            transforms.Resize((356, 356)),\n","            transforms.RandomCrop((299, 299)),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","        ]\n","    )"],"metadata":{"id":"5ee_qkN_u1Rl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 40\n","learning_rate = 0.00001\n","train_CNN = False\n","batch_size = 32\n","shuffle = True\n","pin_memory = True\n","num_workers = 1\n","%store learning_rate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRSaWJ7avCeG","executionInfo":{"status":"ok","timestamp":1670139822187,"user_tz":-540,"elapsed":4,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"50f52751-25a3-4d5f-8323-127fbfb2c9d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stored 'learning_rate' (float)\n"]}]},{"cell_type":"code","source":["dataset = Damage_location(training+front,training+side,training+rear,\"damage_locations.csv\",transform=transform)\n","\n","train_set, validation_set = torch.utils.data.random_split(dataset,[1000,150])\n","train_loader = DataLoader(dataset=train_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n","validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle, batch_size=batch_size,num_workers=num_workers, pin_memory=pin_memory)\n","from google.colab import files\n","# files.download('dataset')\n","\n","# %store dataset"],"metadata":{"id":"uH0SfZHsu3Zt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_variable(): \n","  return dataset,train_set,validation_set,train_loader,validation_loader"],"metadata":{"id":"hsPVnurgu2xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%store dataset\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N70mCDIkwnjf","executionInfo":{"status":"ok","timestamp":1670136882800,"user_tz":-540,"elapsed":3,"user":{"displayName":"Eugen Coroi","userId":"04782466448468484864"}},"outputId":"f7be53e1-2d7b-411e-d8ad-75ba9e2cdb4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning:dataset is <__main__.Damage_location object at 0x7f4f962670d0>\n","Proper storage of interactively declared classes (or instances\n","of those classes) is not possible! Only instances\n","of classes in real modules on file system can be %store'd.\n","\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","a = [dataset,train_set,train_loader,validation_loader]\n","\n","# Choose a file name\n","file_name = \"sharedfile\"\n","\n","# Open the file for writing\n","with open(file_name,'wb') as my_file_obj:\n","    pickle.dump(a,my_file_obj)   \n","\n","# The file you have just saved can be opened in a different session\n","# (or iPython notebook) and the contents will be preserved.\n","\n","# # Now select the (same) file to open (e.g. in another notebook)\n","# file_name = \"sharedfile\"\n","# # Open the file for reading\n","# file_object = open(file_Name,'r')  \n","# # load the object from the file into var b\n","# b = pickle.load(file_object)  \n","\n","# print(b)\n","# >>> ['test value','test value 2','test value 3']"],"metadata":{"id":"5XwvPINL6kc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fLvNOjfj7Upr"},"execution_count":null,"outputs":[]}]}